{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kDaZQMtFMc7",
        "outputId": "9018c395-8aed-432f-b735-c9b2c222dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ldchXH-eHdPB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh29uqsbFX6C",
        "outputId": "5d647612-74fd-450b-b55d-c0499350d0cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'question', 'answer', 'distractor1', 'distractor2',\n",
            "       'distractor(unsure)', 'label', 'choice_list', 'choice_order'],\n",
            "      dtype='object') (456, 9)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train = pd.DataFrame.from_records(np.load('/content/drive/MyDrive/Colab Notebooks/NLP_Dataset/SP-train.npy',allow_pickle=True))\n",
        "train, test = train_test_split(train, test_size=0.1, random_state=42)\n",
        "print(train.columns, train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FT2c0Fq4Y95p"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    processed_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        question = row['question']\n",
        "        choices = [row['answer'], row['distractor1'], row['distractor2'], row['distractor(unsure)']]\n",
        "        for choice in choices:\n",
        "            label = 1 if choice == row['answer'] else 0\n",
        "            processed_data.append((question, choice, label))\n",
        "    return pd.DataFrame(processed_data, columns=['question', 'choice', 'label'])\n",
        "\n",
        "\n",
        "train = preprocess_data(train)\n",
        "val_data = preprocess_data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h-znoKYzZEv2"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset):\n",
        "    def __init__(self, questions, answers, labels, tokenizer, max_len):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        question = str(self.questions[item])\n",
        "        answer = str(self.answers[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            question,\n",
        "            answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'question_answer_text': question + \" \" + answer,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "576AaFzUzL27"
      },
      "outputs": [],
      "source": [
        "class ModelPredictor:\n",
        "    def __init__(self, model, tokenizer, device, val_loader, max_len=256):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.val_loader = val_loader\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_loader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['labels'].to(self.device)\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
        "                correct_predictions += (predictions == labels).sum().item()\n",
        "                total_predictions += labels.size(0)\n",
        "\n",
        "        return correct_predictions / total_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKYU93XgXFYN",
        "outputId": "85fa37d1-8a0f-4282-b440-b158984f644d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of YosoForSequenceClassification were not initialized from the model checkpoint at uw-madison/yoso-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Epoch: 0 ------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114/114 [01:24<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 loss: 0.574893490787138\n",
            "Mean Correctness on Validation Set: 0.75\n",
            "Change in correctness on Validation Set: 0.75\n",
            "----------------------------------\n",
            "\n",
            "\n",
            "------------ Epoch: 1 ------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 114/114 [01:26<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 loss: 0.569563616263239\n",
            "Mean Correctness on Validation Set: 0.75\n",
            "Change in correctness on Validation Set: 0.0\n",
            "----------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#from transformers import AutoTokenizer, XLMRobertaForMultipleChoice\n",
        "#from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from transformers import AutoTokenizer, YosoForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "# model = XLMRobertaForMultipleChoice.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"uw-madison/yoso-4096\")\n",
        "model = YosoForSequenceClassification.from_pretrained(\"uw-madison/yoso-4096\")\n",
        "#model.eval()\n",
        "\n",
        "\n",
        "max_len = 256\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "val_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "train_dataset = QADataset(train['question'], train['choice'], train['label'], tokenizer, max_len)\n",
        "val_dataset = QADataset(val_data['question'], val_data['choice'], val_data['label'], tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "#train_loader = train_dataset\n",
        "#val_loader = val_dataset\n",
        "\n",
        "# Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "last_correctness = 0\n",
        "epsilon = 0.0001\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'\\n------------ Epoch: {epoch} ------------')\n",
        "    model.train()\n",
        "    losses = np.array([])\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        # print(\"labels\",labels.shape)\n",
        "        # print(\"input_id\",input_ids.shape)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        losses = np.append(losses, loss.item())\n",
        "    print(f\"Epoch: {epoch} loss: {np.mean(losses)}\")\n",
        "    predictor = ModelPredictor(model, tokenizer, device, val_loader, max_len)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mean_correctness = predictor.evaluate()\n",
        "    print(f\"Mean Correctness on Validation Set: {mean_correctness}\")\n",
        "    print(f\"Change in correctness on Validation Set: {mean_correctness - last_correctness}\")\n",
        "    print(f\"----------------------------------\\n\")\n",
        "    if mean_correctness - last_correctness <= epsilon:\n",
        "        break\n",
        "    else:\n",
        "        last_correctness = mean_correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gkyahMQRansT"
      },
      "outputs": [],
      "source": [
        "class ModelPredictorQA:\n",
        "    def __init__(self, model, tokenizer, device, max_len=256):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def predict(self, row):\n",
        "        question = row['question']\n",
        "        choices = row['choice_list']\n",
        "        max_score = -1\n",
        "        answer_index = -1\n",
        "\n",
        "        for i, choice in enumerate(choices):\n",
        "            # Tokenize the question and choice\n",
        "            encoding = self.tokenizer.encode_plus(\n",
        "                question,\n",
        "                choice,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_len,\n",
        "                return_token_type_ids=False,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True,\n",
        "                return_tensors='pt',\n",
        "                truncation=True\n",
        "            )\n",
        "\n",
        "            input_ids = encoding['input_ids'].to(self.device)\n",
        "            attention_mask = encoding['attention_mask'].to(self.device)\n",
        "\n",
        "            # Get model predictions\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "                predictions = torch.softmax(logits, dim=1)[:, 1]\n",
        "                score = predictions.item()\n",
        "\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                answer_index = i\n",
        "\n",
        "        return answer_index, row['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QOvoHUh5zt0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac8e967-b846-46cf-d5df-1cfc160967a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row: 173, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 274, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 492, Predicted Answer Index: 0, Correct Answer Index: 1\n",
            "Row: 72, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 453, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 316, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 218, Predicted Answer Index: 0, Correct Answer Index: 3\n",
            "Row: 9, Predicted Answer Index: 1, Correct Answer Index: 2\n",
            "Row: 415, Predicted Answer Index: 3, Correct Answer Index: 1\n",
            "Row: 78, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 323, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 474, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 424, Predicted Answer Index: 1, Correct Answer Index: 2\n",
            "Row: 195, Predicted Answer Index: 2, Correct Answer Index: 3\n",
            "Row: 278, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 422, Predicted Answer Index: 0, Correct Answer Index: 2\n",
            "Row: 79, Predicted Answer Index: 0, Correct Answer Index: 2\n",
            "Row: 455, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 210, Predicted Answer Index: 1, Correct Answer Index: 3\n",
            "Row: 498, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 172, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 375, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 362, Predicted Answer Index: 3, Correct Answer Index: 1\n",
            "Row: 468, Predicted Answer Index: 1, Correct Answer Index: 3\n",
            "Row: 153, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 2, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 336, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 73, Predicted Answer Index: 2, Correct Answer Index: 0\n",
            "Row: 307, Predicted Answer Index: 0, Correct Answer Index: 2\n",
            "Row: 204, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 68, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 90, Predicted Answer Index: 1, Correct Answer Index: 2\n",
            "Row: 33, Predicted Answer Index: 1, Correct Answer Index: 2\n",
            "Row: 70, Predicted Answer Index: 1, Correct Answer Index: 0\n",
            "Row: 0, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "Row: 11, Predicted Answer Index: 2, Correct Answer Index: 1\n",
            "0.2941\n"
          ]
        }
      ],
      "source": [
        "predictor = ModelPredictorQA(model, tokenizer, device, max_len)\n",
        "results = []\n",
        "\n",
        "for i, row in test.iterrows():\n",
        "    answer_index, label = predictor.predict(row)\n",
        "    if answer_index != label:\n",
        "        print(f\"Row: {i}, Predicted Answer Index: {answer_index}, Correct Answer Index: {label}\")\n",
        "    results.append(answer_index == label)\n",
        "\n",
        "print(round(sum(results) / len(results),4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}